for (i in sample.int(n_samp,10)) {
lines(gz[,i] ~ z_days, col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz - lower_gz)
set.seed(123)
gw <- sample_marginal(quad, n_samp)
mean_gw  <- apply(gw$samps,1, mean)
upper_gw  <- apply(gw$samps,1, quantile, p = 0.975)
lower_gw  <- apply(gw$samps,1, quantile, p = 0.025)
### Check hyperparameter:
# Plot of theta1 posterior
prec_marg <- quad$marginals[[1]]
logpostsigma <- compute_pdf_and_cdf(prec_marg,list(totheta = function(x) -2*log(x),fromtheta = function(x) exp(-x/2)),interpolation = 'spline')
with(logpostsigma,plot(transparam,pdf_transparam,type='l'))
# Plot of theta2 posterior
prec_marg <- quad$marginals[[2]]
logpostsigma <- compute_pdf_and_cdf(prec_marg,list(totheta = function(x) -2*log(x),fromtheta = function(x) exp(-x/2)),interpolation = 'spline')
with(logpostsigma,plot(transparam,pdf_transparam,type='l'))
### Takeout
z_location <- which(all_grid %in% z)
construct_Z_matrix <- construct_A(all_grid, z_location)
gz <- construct_Z_matrix %*% gw$samps[1:ncol(Q1), ]
U_1st_Deriv <- apply(gz, 2, compute_deriv, order = 1)
U_2nd_Deriv <- apply(gz, 2, compute_deriv, order = 2)
mean_gz  <- apply(gz,1, mean)
upper_gz  <- apply(gz,1, quantile, p = 0.975)
lower_gz  <- apply(gz,1, quantile, p = 0.025)
z_days <- allDays
z_data <- data.frame(mean = mean_gz, z = z, date = z_days)
mean_gz_1st  <- apply(U_1st_Deriv,1, mean)
upper_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.975)
lower_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.025)
z_1st <- data.frame(mean = mean_gz_1st, z = z[-1], date = z_days[-1])
plot(mean_gz ~ z_days, type = 'l', data = z_data, xlab = "Time", ylab = expression(f[np]))
lines(upper_gz ~ z_days, lty = 'dashed', col = 'orange')
lines(lower_gz ~ z_days, lty = 'dashed', col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(gz[,i] ~ z_days, col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz - lower_gz)
upper_gz  <- apply(gz,1, quantile, p = 0.95)
lower_gz  <- apply(gz,1, quantile, p = 0.05)
mean(upper_gz - lower_gz)
### Takeout
z_location <- which(all_grid %in% z)
construct_Z_matrix <- construct_A(all_grid, z_location)
gz <- construct_Z_matrix %*% gw$samps[1:ncol(Q1), ]
U_1st_Deriv <- apply(gz, 2, compute_deriv, order = 1)
U_2nd_Deriv <- apply(gz, 2, compute_deriv, order = 2)
mean_gz  <- apply(gz,1, mean)
upper_gz  <- apply(gz,1, quantile, p = 0.95)
lower_gz  <- apply(gz,1, quantile, p = 0.05)
z_days <- allDays
z_data <- data.frame(mean = mean_gz, z = z, date = z_days)
mean_gz_1st  <- apply(U_1st_Deriv,1, mean)
upper_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.975)
lower_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.025)
z_1st <- data.frame(mean = mean_gz_1st, z = z[-1], date = z_days[-1])
plot(mean_gz ~ z_days, type = 'l', data = z_data, xlab = "Time", ylab = expression(f[np]))
lines(upper_gz ~ z_days, lty = 'dashed', col = 'orange')
lines(lower_gz ~ z_days, lty = 'dashed', col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(gz[,i] ~ z_days, col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz - lower_gz)
### MCI: 0.6481862 for 99 percent
### MCI: 0.4896828 for 95 percent
### MCI: 0.4084033 for 90 percent
plot(mean_gz_1st ~ date, type = 'l', data = z_1st, ylim = c(-0.01,0.1), xlab = "Time", ylab = expression(paste(f[np], ":1st derivative ", sep = "\ ")))
lines(upper_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
lines(lower_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(U_1st_Deriv[,i] ~ z_days[-1], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_1st - lower_gz_1st)
upper_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.995)
lower_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.005)
z_1st <- data.frame(mean = mean_gz_1st, z = z[-1], date = z_days[-1])
plot(mean_gz ~ z_days, type = 'l', data = z_data, xlab = "Time", ylab = expression(f[np]))
lines(upper_gz ~ z_days, lty = 'dashed', col = 'orange')
lines(lower_gz ~ z_days, lty = 'dashed', col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(gz[,i] ~ z_days, col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz - lower_gz)
### MCI: 0.6481862 for 99 percent
### MCI: 0.4896828 for 95 percent
### MCI: 0.4084033 for 90 percent
plot(mean_gz_1st ~ date, type = 'l', data = z_1st, ylim = c(-0.01,0.1), xlab = "Time", ylab = expression(paste(f[np], ":1st derivative ", sep = "\ ")))
lines(upper_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
lines(lower_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(U_1st_Deriv[,i] ~ z_days[-1], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_1st - lower_gz_1st)
upper_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.95)
lower_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.05)
z_1st <- data.frame(mean = mean_gz_1st, z = z[-1], date = z_days[-1])
plot(mean_gz ~ z_days, type = 'l', data = z_data, xlab = "Time", ylab = expression(f[np]))
lines(upper_gz ~ z_days, lty = 'dashed', col = 'orange')
lines(lower_gz ~ z_days, lty = 'dashed', col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(gz[,i] ~ z_days, col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz - lower_gz)
### MCI: 0.6481862 for 99 percent
### MCI: 0.4896828 for 95 percent
### MCI: 0.4084033 for 90 percent
plot(mean_gz_1st ~ date, type = 'l', data = z_1st, ylim = c(-0.01,0.1), xlab = "Time", ylab = expression(paste(f[np], ":1st derivative ", sep = "\ ")))
lines(upper_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
lines(lower_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(U_1st_Deriv[,i] ~ z_days[-1], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_1st - lower_gz_1st)
upper_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.975)
lower_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.025)
z_1st <- data.frame(mean = mean_gz_1st, z = z[-1], date = z_days[-1])
plot(mean_gz ~ z_days, type = 'l', data = z_data, xlab = "Time", ylab = expression(f[np]))
lines(upper_gz ~ z_days, lty = 'dashed', col = 'orange')
lines(lower_gz ~ z_days, lty = 'dashed', col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(gz[,i] ~ z_days, col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz - lower_gz)
### MCI: 0.6481862 for 99 percent
### MCI: 0.4896828 for 95 percent
### MCI: 0.4084033 for 90 percent
plot(mean_gz_1st ~ date, type = 'l', data = z_1st, ylim = c(-0.01,0.1), xlab = "Time", ylab = expression(paste(f[np], ":1st derivative ", sep = "\ ")))
lines(upper_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
lines(lower_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(U_1st_Deriv[,i] ~ z_days[-1], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_1st - lower_gz_1st)
mean_gz_2nd  <- apply(U_2nd_Deriv,1, mean)
upper_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.975)
lower_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.025)
z_2nd <- data.frame(mean = mean_gz_2nd, z = z[-c(1,2)], date = z_days[-c(1,2)])
plot(mean_gz_2nd ~ date, type = 'l', data = z_2nd, ylim = c(-0.01,0.01), xlab = "Time", ylab = expression(paste(f[np], ":2nd derivative ", sep = "\ ")))
lines(upper_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
lines(lower_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
for (i in sample.int(n_samp,3)) {
lines(U_2nd_Deriv[,i] ~ z_days[-c(1,2)], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_2nd - lower_gz_2nd)
mean_gz_2nd  <- apply(U_2nd_Deriv,1, mean)
upper_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.995)
lower_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.005)
z_2nd <- data.frame(mean = mean_gz_2nd, z = z[-c(1,2)], date = z_days[-c(1,2)])
plot(mean_gz_2nd ~ date, type = 'l', data = z_2nd, ylim = c(-0.01,0.01), xlab = "Time", ylab = expression(paste(f[np], ":2nd derivative ", sep = "\ ")))
lines(upper_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
lines(lower_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
for (i in sample.int(n_samp,3)) {
lines(U_2nd_Deriv[,i] ~ z_days[-c(1,2)], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_2nd - lower_gz_2nd)
mean_gz_2nd  <- apply(U_2nd_Deriv,1, mean)
upper_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.95)
lower_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.05)
z_2nd <- data.frame(mean = mean_gz_2nd, z = z[-c(1,2)], date = z_days[-c(1,2)])
plot(mean_gz_2nd ~ date, type = 'l', data = z_2nd, ylim = c(-0.01,0.01), xlab = "Time", ylab = expression(paste(f[np], ":2nd derivative ", sep = "\ ")))
lines(upper_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
lines(lower_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
for (i in sample.int(n_samp,3)) {
lines(U_2nd_Deriv[,i] ~ z_days[-c(1,2)], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_2nd - lower_gz_2nd)
### MCI: 0.01997148 for 99 percent
### MCI: 0.01419562 for 95 percent
### MCI: 0.01156123 for 90 percent
### MCI: 0.04770736 for 99 percent
### MCI: 0.03491584 for 95 percent
### MCI: 0.02883124 for 90 percent
### MCI: 0.6481862 for 99 percent
### MCI: 0.4896828 for 95 percent
### MCI: 0.4084033 for 90 percent
gw_rw2 <- sample_marginal(quad, n_samp)
gw_arima <- sample_marginal(quad2, n_samp)
set.seed(123)
gw_rw2 <- sample_marginal(quad, n_samp)
gw_arima <- sample_marginal(quad2, n_samp)
### Study the maximum of curves of each method:
set.seed(123)
gw_rw2 <- sample_marginal(quad, n_samp)
gw_arima <- sample_marginal(quad2, n_samp)
gz_rw2 <- construct_Z_matrix %*% gw_rw2$samps[1:ncol(Q1), ]
gz_arima <- construct_Z_matrix %*% gw_arima$samps[1:ncol(Q1), ]
### Study the maximum of curves of each method:
set.seed(123)
gw_rw2 <- sample_marginal(quad, n_samp)
gw_arima <- sample_marginal(quad2, n_samp)
gz_rw2 <- construct_Z_matrix %*% gw_rw2$samps[1:ncol(Q1), ]
gz_arima <- construct_Z_matrix %*% gw_arima$samps[1:ncol(Q2), ]
gz_rw2
dim(gz_rw2)
gz_rw2_f_max <- apply(gz_rw2, 2, max)
gz_arima_f_max <- apply(gz_arima, 2, max)
gz_rw2_f_max
hist(gz_rw2_f_max)
hist(gz_arima_f_max)
summary(gz_rw2_f_max)
summary(gz_arima_f_max)
U_1st_Deriv_rw2 <- apply(gz_rw2, 2, compute_deriv, order = 1)
U_2nd_Deriv_rw2 <- apply(gz_rw2, 2, compute_deriv, order = 2)
U_1st_Deriv_rw2 <- apply(gz_rw2, 2, compute_deriv, order = 1)
U_2nd_Deriv_rw2 <- apply(gz_rw2, 2, compute_deriv, order = 2)
gz_rw2_f1st_max <- apply(U_1st_Deriv_rw2, 2, max)
summary(gz_rw2_f_max)
summary(gz_rw2_f1st_max)
U_1st_Deriv_arima <- apply(gz_arima, 2, compute_deriv, order = 1)
U_2nd_Deriv_arima <- apply(gz_arima, 2, compute_deriv, order = 2)
gz_arima_f1st_max <- apply(U_1st_Deriv_arima, 2, max)
summary(gz_arima_f1st_max)
fivenum(gz_arima_f1st_max)
sd(gz_arima_f1st_max)
sd(gz_rw2_f1st_max)
hist(gz_rw2_f1st_max)
hist(gz_arima_f1st_max)
gz_rw2_f2nd_max <- apply(U_2nd_Deriv_rw2, 2, max)
summary(gz_rw2_f2nd_max)
hist(gz_rw2_f2nd_max)
gz_arima_f2nd_max <- apply(U_2nd_Deriv_arima, 2, max)
summary(gz_arima_f2nd_max)
hist(gz_arima_f2nd_max)
f2nd_max_data <- tibble(max = c(gz_arima_f2nd_max,gz_rw2_f2nd_max), types = c(rep("ARIMA", length(gz_arima_f2nd_max)), rep("RW2", length(gz_rw2_f2nd_max))))
f2nd_max_data %>% ggplot(aes(x = max, fill = type)) + geom_histogram()
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_histogram()
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_density()
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_density(bw = 0.1)
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_density(bw = 0.01)
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_density(bw = 0.001)
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_density(bw = 0.005)
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_density(bw = 0.003)
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_density(bw = 0.001)
f2nd_max_data %>% ggplot(aes(x = max, group = types)) + geom_density(bw = 0.001)
f2nd_max_data %>% ggplot(aes(x = max, group = types)) + geom_histogram(bw = 0.001)
f2nd_max_data %>% ggplot(aes(x = max, group = types)) + geom_histogram(bins = 50)
f2nd_max_data %>% ggplot(aes(x = max, fills = types)) + geom_histogram(bins = 50)
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_histogram(bins = 50)
f2nd_max_data %>% ggplot(aes(x = max, fill = types)) + geom_boxplot()
f2nd_max_data %>% ggplot(aes(x = max, y = types)) + geom_boxplot()
f2nd_max_data <- tibble(Max = c(gz_arima_f2nd_max,gz_rw2_f2nd_max), Types = c(rep("ARIMA", length(gz_arima_f2nd_max)), rep("RW2", length(gz_rw2_f2nd_max))))
f2nd_max_data %>% ggplot(aes(x = Max, y = Types)) + geom_boxplot()
f1st_max_data <- tibble(Max = c(gz_arima_f1st_max,gz_rw2_f1st_max), Types = c(rep("ARIMA", length(gz_arima_f1st_max)), rep("RW2", length(gz_rw2_f1st_max))))
f1st_max_data %>% ggplot(aes(x = Max, y = Types)) + geom_boxplot()
source("/Users/ziangzhang/Documents/research_comps/RealData/function_used.R")
dyn.load(dynlib("Real_Smoothing"))
#### Load data, select rows
cUrl = paste0("http://scrippsco2.ucsd.edu/assets/data/atmospheric/",
"stations/flask_co2/daily/daily_flask_co2_mlo.csv")
cFile = basename(cUrl)
if (!file.exists(cFile)) download.file(cUrl, cFile)
co2s = read.table(cFile, header = FALSE, sep = ",",
skip = 69, stringsAsFactors = FALSE, col.names = c("day",
"time", "junk1", "junk2", "Nflasks", "quality",
"co2"))
co2s$date = strptime(paste(co2s$day, co2s$time), format = "%Y-%m-%d %H:%M",
tz = "UTC")
# remove low-quality measurements
co2s = co2s[co2s$quality == 0, ]
co2s$day = as.Date(co2s$date)
toAdd = data.frame(day = seq(max(co2s$day) + 3, as.Date("2022/1/1"),
by = "7 days"), co2 = NA)
co2ext = rbind(co2s[, colnames(toAdd)], toAdd)
timeOrigin = as.Date("2000/1/1")
co2ext$timeYears = round(as.numeric(co2ext$day - timeOrigin)/365.25,
2)
co2ext$cos12 = cos(2 * pi * co2ext$timeYears)
co2ext$sin12 = sin(2 * pi * co2ext$timeYears)
co2ext$cos6 = cos(2 * 2 * pi * co2ext$timeYears)
co2ext$sin6 = sin(2 * 2 * pi * co2ext$timeYears)
co2ext$dayInt = as.integer(co2ext$day)
# ### Reduce the size of the dataset:
co2ext <- co2ext %>% filter(day >= "1990-01-01")
### Now use the full data, but look at a weekly observed grid.
allDays = seq(from = min(co2ext$day), to = max(co2ext$day),
by = "7 day")
observed_dataset <- co2ext %>% filter(!is.na(co2ext$co2)) %>% select(c("co2", "cos12", "sin12", "cos6", "sin6", "dayInt", "day"))
nrow(observed_dataset)
co2s$date = strptime(paste(co2s$day, co2s$time), format = "%Y-%m-%d %H:%M",
tz = "UTC")
# remove low-quality measurements
co2s = co2s[co2s$quality == 0, ]
co2s$day = as.Date(co2s$date)
toAdd = data.frame(day = seq(max(co2s$day) + 3, as.Date("2022/1/1"),
by = "7 days"), co2 = NA)
co2ext = rbind(co2s[, colnames(toAdd)], toAdd)
timeOrigin = as.Date("2000/1/1")
co2ext$timeYears = round(as.numeric(co2ext$day - timeOrigin)/365.25,
2)
co2ext$cos12 = cos(2 * pi * co2ext$timeYears)
co2ext$sin12 = sin(2 * pi * co2ext$timeYears)
co2ext$cos6 = cos(2 * 2 * pi * co2ext$timeYears)
co2ext$sin6 = sin(2 * 2 * pi * co2ext$timeYears)
co2ext$dayInt = as.integer(co2ext$day)
# ### Reduce the size of the dataset:
co2ext <- co2ext %>% filter(day >= "1990-01-01")
### Now use the full data, but look at a weekly observed grid.
allDays = seq(from = min(co2ext$day), to = max(co2ext$day),
by = "7 day")
observed_dataset <- co2ext %>% filter(!is.na(co2ext$co2)) %>% select(c("co2", "cos12", "sin12", "cos6", "sin6", "dayInt", "day"))
designX <- as(as.matrix(observed_dataset[,-c(1,6,7)]), "dgTMatrix")
x_grid <- observed_dataset$dayInt
z <- as.integer(allDays)
z_grid <- z[!z %in% x_grid]
all_grid <- sort(c(x_grid, z_grid))
x_locations <- which(all_grid %in% x_grid)
myA <- construct_A(all_grid = all_grid, x_indx = x_locations)
n <- length(all_grid)
designB <- as(myA, "dgTMatrix")
d <- diff(all_grid)
H <- compute_H_rue(d,n = length(all_grid))
B <- compute_B(d,n = length(all_grid))
A <- compute_A(d, n = length(all_grid))
#####################################################################
#####################################################################
#####################################################################
#####################################################################
###### RW2:
Q1 <- t(H) %*% solve(A) %*% H
Q1 <- as(Q1 + Diagonal(n, x = 1e-15), "dgTMatrix")
tmbdat <- list(
# Design matrix
X = designX,
B = designB,
# Penalty(Precision) matrix
P = Q1,
# Log determinant of penalty matrix (without the sigma part)
# logPdet = as.numeric(sum(log(sort(all_values)[-(1:2)]))),
logPdet = as.numeric(determinant(Q1,logarithm = T)$modulus),
# Response
y = observed_dataset$co2,
# PC Prior params
u1 = 0.001,
alpha1 = 0.5,
u2 = 1,
alpha2 = 0.5,
betaprec = 10^(-6)
)
tmbparams <- list(
W = c(rep(0, n), rep(0, ncol(designX))), # W = c(U,beta); U = B-Spline coefficients
theta1 = 0, # -2log(sigma)
theta2 = 0
)
ff <- TMB::MakeADFun(
data = tmbdat,
parameters = tmbparams,
random = "W",
DLL = "Real_Smoothing",
silent = TRUE
)
# Hessian not implemented for RE models
ff$he <- function(w) numDeriv::jacobian(ff$gr,w)
# AGHQ
set.seed(123)
start_time <- Sys.time()
quad <- aghq::marginal_laplace_tmb(ff,5,c(0,0))
Sys.time() - start_time
length(z)
z_days <- allDays
cFile = basename(cUrl)
if (!file.exists(cFile)) download.file(cUrl, cFile)
co2s = read.table(cFile, header = FALSE, sep = ",",
skip = 69, stringsAsFactors = FALSE, col.names = c("day",
"time", "junk1", "junk2", "Nflasks", "quality",
"co2"))
co2s$date = strptime(paste(co2s$day, co2s$time), format = "%Y-%m-%d %H:%M",
tz = "UTC")
# remove low-quality measurements
co2s = co2s[co2s$quality == 0, ]
co2s$day = as.Date(co2s$date)
toAdd = data.frame(day = seq(max(co2s$day) + 3, as.Date("2022/1/1"),
by = "7 days"), co2 = NA)
co2ext = rbind(co2s[, colnames(toAdd)], toAdd)
timeOrigin = as.Date("2000/1/1")
co2ext$timeYears = round(as.numeric(co2ext$day - timeOrigin)/365.25,
2)
co2ext$cos12 = cos(2 * pi * co2ext$timeYears)
co2ext$sin12 = sin(2 * pi * co2ext$timeYears)
co2ext$cos6 = cos(2 * 2 * pi * co2ext$timeYears)
co2ext$sin6 = sin(2 * 2 * pi * co2ext$timeYears)
co2ext$dayInt = as.integer(co2ext$day)
# ### Reduce the size of the dataset:
co2ext <- co2ext %>% filter(day >= "2010-01-01")
### Now use the full data, but look at a weekly observed grid.
allDays = seq(from = min(co2ext$day), to = max(co2ext$day),
by = "7 day")
observed_dataset <- co2ext %>% filter(!is.na(co2ext$co2)) %>% select(c("co2", "cos12", "sin12", "cos6", "sin6", "dayInt", "day"))
designX <- as(as.matrix(observed_dataset[,-c(1,6,7)]), "dgTMatrix")
x_grid <- observed_dataset$dayInt
z <- as.integer(allDays)
z_grid <- z[!z %in% x_grid]
all_grid <- sort(c(x_grid, z_grid))
x_locations <- which(all_grid %in% x_grid)
myA <- construct_A(all_grid = all_grid, x_indx = x_locations)
n <- length(all_grid)
designB <- as(myA, "dgTMatrix")
d <- diff(all_grid)
H <- compute_H_rue(d,n = length(all_grid))
B <- compute_B(d,n = length(all_grid))
D <- H[-c(1,n),]
R <- B[-c(1,n), -c(1,n)]
d <- diff(all_grid)
H <- compute_H_rue(d,n = length(all_grid))
B <- compute_B(d,n = length(all_grid))
A <- compute_A(d, n = length(all_grid))
Q1 <- t(H) %*% solve(A) %*% H
Q1 <- as(Q1 + Diagonal(n, x = 1e-15), "dgTMatrix")
tmbdat <- list(
# Design matrix
X = designX,
B = designB,
# Penalty(Precision) matrix
P = Q1,
# Log determinant of penalty matrix (without the sigma part)
# logPdet = as.numeric(sum(log(sort(all_values)[-(1:2)]))),
logPdet = as.numeric(determinant(Q1,logarithm = T)$modulus),
# Response
y = observed_dataset$co2,
# PC Prior params
u1 = 0.001,
alpha1 = 0.5,
u2 = 1,
alpha2 = 0.5,
betaprec = 10^(-6)
)
tmbparams <- list(
W = c(rep(0, n), rep(0, ncol(designX))), # W = c(U,beta); U = B-Spline coefficients
theta1 = 0, # -2log(sigma)
theta2 = 0
)
ff <- TMB::MakeADFun(
data = tmbdat,
parameters = tmbparams,
random = "W",
DLL = "Real_Smoothing",
silent = TRUE
)
# Hessian not implemented for RE models
ff$he <- function(w) numDeriv::jacobian(ff$gr,w)
# AGHQ
set.seed(123)
start_time <- Sys.time()
quad <- aghq::marginal_laplace_tmb(ff,5,c(0,0))
Sys.time() - start_time
## takes 2.55 secs
set.seed(123)
gw <- sample_marginal(quad, n_samp)
mean_gw  <- apply(gw$samps,1, mean)
upper_gw  <- apply(gw$samps,1, quantile, p = 0.975)
lower_gw  <- apply(gw$samps,1, quantile, p = 0.025)
### Check hyperparameter:
# Plot of theta1 posterior
prec_marg <- quad$marginals[[1]]
logpostsigma <- compute_pdf_and_cdf(prec_marg,list(totheta = function(x) -2*log(x),fromtheta = function(x) exp(-x/2)),interpolation = 'spline')
with(logpostsigma,plot(transparam,pdf_transparam,type='l'))
# Plot of theta2 posterior
prec_marg <- quad$marginals[[2]]
logpostsigma <- compute_pdf_and_cdf(prec_marg,list(totheta = function(x) -2*log(x),fromtheta = function(x) exp(-x/2)),interpolation = 'spline')
with(logpostsigma,plot(transparam,pdf_transparam,type='l'))
### Takeout
z_location <- which(all_grid %in% z)
construct_Z_matrix <- construct_A(all_grid, z_location)
gz <- construct_Z_matrix %*% gw$samps[1:ncol(Q1), ]
U_1st_Deriv <- apply(gz, 2, compute_deriv, order = 1)
U_2nd_Deriv <- apply(gz, 2, compute_deriv, order = 2)
mean_gz  <- apply(gz,1, mean)
upper_gz  <- apply(gz,1, quantile, p = 0.975)
lower_gz  <- apply(gz,1, quantile, p = 0.025)
z_days <- allDays
z_data <- data.frame(mean = mean_gz, z = z, date = z_days)
mean_gz_1st  <- apply(U_1st_Deriv,1, mean)
upper_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.975)
lower_gz_1st  <- apply(U_1st_Deriv,1, quantile, p = 0.025)
z_1st <- data.frame(mean = mean_gz_1st, z = z[-1], date = z_days[-1])
plot(mean_gz ~ z_days, type = 'l', data = z_data, xlab = "Time", ylab = expression(f[np]))
lines(upper_gz ~ z_days, lty = 'dashed', col = 'orange')
lines(lower_gz ~ z_days, lty = 'dashed', col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(gz[,i] ~ z_days, col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz - lower_gz)
plot(mean_gz_1st ~ date, type = 'l', data = z_1st, ylim = c(-0.01,0.1), xlab = "Time", ylab = expression(paste(f[np], ":1st derivative ", sep = "\ ")))
lines(upper_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
lines(lower_gz_1st ~ date, lty = 'dashed', data = z_1st, col = 'orange')
for (i in sample.int(n_samp,10)) {
lines(U_1st_Deriv[,i] ~ z_days[-1], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_1st - lower_gz_1st)
mean_gz_2nd  <- apply(U_2nd_Deriv,1, mean)
upper_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.95)
lower_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.05)
z_2nd <- data.frame(mean = mean_gz_2nd, z = z[-c(1,2)], date = z_days[-c(1,2)])
plot(mean_gz_2nd ~ date, type = 'l', data = z_2nd, ylim = c(-0.01,0.01), xlab = "Time", ylab = expression(paste(f[np], ":2nd derivative ", sep = "\ ")))
lines(upper_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
lines(lower_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
for (i in sample.int(n_samp,3)) {
lines(U_2nd_Deriv[,i] ~ z_days[-c(1,2)], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_2nd - lower_gz_2nd)
mean_gz_2nd  <- apply(U_2nd_Deriv,1, mean)
upper_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.975)
lower_gz_2nd  <- apply(U_2nd_Deriv,1, quantile, p = 0.025)
z_2nd <- data.frame(mean = mean_gz_2nd, z = z[-c(1,2)], date = z_days[-c(1,2)])
plot(mean_gz_2nd ~ date, type = 'l', data = z_2nd, ylim = c(-0.01,0.01), xlab = "Time", ylab = expression(paste(f[np], ":2nd derivative ", sep = "\ ")))
lines(upper_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
lines(lower_gz_2nd~date, lty = 'dashed', data = z_2nd, col = 'orange')
for (i in sample.int(n_samp,3)) {
lines(U_2nd_Deriv[,i] ~ z_days[-c(1,2)], col = rgb(240, 0, 0, max = 255, alpha = 40, names = "grey"))
}
mean(upper_gz_2nd - lower_gz_2nd)
