@article{rw2,
author = {Lindgren, Finn and Rue, Håvard},
title = {On the Second-Order Random Walk Model for Irregular Locations},
journal = {Scandinavian Journal of Statistics},
volume = {35},
number = {4},
pages = {691-700},
keywords = {Galerkin approximation, integrated Wiener process, intrinsic Gaussian Markov random fields, numerical methods for sparse matrices, second-order random walk},
year = {2008}
}


@article{bayesianPsplines,
author = {Stefan Lang and Andreas Brezger},
title = {Bayesian P-Splines},
journal = {Journal of Computational and Graphical Statistics},
volume = {13},
number = {1},
pages = {183-212},
year  = {2004},
publisher = {Taylor & Francis}
}


@article{wahba,
 ISSN = {00359246},
 abstract = {Spline and generalized spline smoothing is shown to be equivalent to Bayesian estimation with a partially improper prior. This result supports the idea that spline smoothing is a natural solution to the regression problem when one is given a set of regression functions but one also wants to hedge against the possibility that the true model is not exactly in the span of the given regression functions. A natural measure of the deviation of the true model from the span of the regression functions comes out of the spline theory in a natural way. An appropriate value of this measure can be estimated from the data and used to constrain the estimated model to have the estimated deviation. Some convergence results and computational tricks are also discussed.},
 author = {Grace Wahba},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {3},
 pages = {364--372},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Improper Priors, Spline Smoothing and the Problem of Guarding Against Model Errors in Regression},
 volume = {40},
 year = {1978}
}


@article{inla,
author = {Rue, Håvard and Martino, Sara and Chopin, Nicolas},
title = {Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {71},
number = {2},
pages = {319-392},
keywords = {Approximate Bayesian inference, Gaussian Markov random fields, Generalized additive mixed models, Laplace approximation, Parallel computing, Sparse matrices, Structured additive regression models},
abstract = {Summary.  Structured additive regression models are perhaps the most commonly used class of models in statistical applications. It includes, among others, (generalized) linear models, (generalized) additive models, smoothing spline models, state space models, semiparametric regression, spatial and spatiotemporal models, log-Gaussian Cox processes and geostatistical and geoadditive models. We consider approximate Bayesian inference in a popular subset of structured additive regression models, latent Gaussian models, where the latent field is Gaussian, controlled by a few hyperparameters and with non-Gaussian response variables. The posterior marginals are not available in closed form owing to the non-Gaussian response variables. For such models, Markov chain Monte Carlo methods can be implemented, but they are not without problems, in terms of both convergence and computational time. In some practical applications, the extent of these problems is such that Markov chain Monte Carlo sampling is simply not an appropriate tool for routine analysis. We show that, by using an integrated nested Laplace approximation and its simplified version, we can directly compute very accurate approximations to the posterior marginals. The main benefit of these approximations is computational: where Markov chain Monte Carlo algorithms need hours or days to run, our approximations provide more precise estimates in seconds or minutes. Another advantage with our approach is its generality, which makes it possible to perform Bayesian analysis in an automatic, streamlined way, and to compute model comparison criteria and various predictive measures so that models can be compared and the model under study can be challenged.},
year = {2009}
}

